install.packages(c("lars", "neuralnet"))
setwd("C:/Users/SON/Dropbox/git/capstone/fifa")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
splitIndex = createDataPartition(Fifa_19$overall, p=.70, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=.70, list = FALSE)
test = Fifa_20[-splitIndex,]
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
library(caret)
library(neuralnet)
#want to make one nerual network not sure how to go about it
model <- neuralnet()
myGrid = expand.grid(mtry = c(1:2), splitrule = c("gini"),
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
str(ttrain
str(train)
str(Fifa_19)
names(Fifa_19)
names(Fifa_20)
sum(names(Fifa_19)==names(Fifa_20))
train=Fifa_19
test=Fifa_20
sum(is.na(train))
sum(is.na(test))
train1 = train %>% mutate_if(is.character,as.numeric)
warning
warning()
str(train1)
test1 = test %>% mutate_if(is.character,as.numeric)
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
myGrid = expand.grid(mtry = c(1:2), splitrule = c("gini"),
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
myGrid = expand.grid(mtry = c(1:2),
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
myGrid = expand.grid(mtry = c(1:2), splitrule='variance'
min.node.size = c(1:2))
myGrid = expand.grid(mtry = c(1:2), splitrule='variance',
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
train1
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
splitIndex = createDataPartition(Fifa_19$overall, p=.30, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=.30, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
test = test %>% mutate_if(is.character, as.numeric)
sum(is.na(train))
colSums(is.na(train))
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
splitIndex = createDataPartition(Fifa_19$overall, p=.30, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=.30, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
train
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=1
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
train
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=.3
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
library(caret)
library(neuralnet)
#want to make one nerual network not sure how to go about it
model <- neuralnet()
myGrid = expand.grid(mtry = c(1:2), splitrule='variance',
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
pred  = predict(model, test)
pred
model
postResample(pred = pred, obs = test$overall)
myGrid = expand.grid(n.trees = c(1:2)
, interaction.depth = c(1:2), shrinkage =c(1:2)
, n.minobsinnode = c(1:2)  )
model= train(overall~.,data=train, method = "gbm",tuneGrid = myGrid)
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
library(lars)
model = lars(overall~., data = train,method="stepwise")
library(lars)
model= train(overall~.,data=train, method = "elasticnet")
library(lars)
model= train(overall~.,data=train, method = "lasso")
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
library(caret)
library(neuralnet)
#want to make one nerual network not sure how to go about it
myGrid = expand.grid(size = c(1:3))
model <- train(overall~.,data = train, method = "mlp", tuneGrid = myGrid)
pred  = predict(model, test)
# Show performance of the model on test data
postResample(pred = pred, obs = test$overall)
library(lars)
install.packages('glmnet')
myGrid = expand.grid(alpha = c(.1, .2, .3), lambda = c(.1)
model= train(overall~.,data=train, method = "glmnet")
library(lars)
install.packages('glmnet')
myGrid = expand.grid(alpha = c(.1, .2, .3), lambda = c(.1))
model= train(overall~.,data=train, method = "glmnet")
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
library(lars)
install.packages('glmnet')
myGrid = expand.grid(alpha = c(1:10)/10, lambda = c(1:10)/10)
model= train(overall~.,data=train, method = "glmnet")
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
install.packages("glmnet")
install.packages("glmnet")
knitr::opts_chunk$set(echo = TRUE)
library(lars)
myGrid = expand.grid(alpha = c(1:10)/10, lambda = c(1:10)/10)
model= train(overall~.,data=train, method = "glmnet")
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=.3
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
library(lars)
myGrid = expand.grid(alpha = c(1:10)/10, lambda = c(1:10)/10)
model= train(overall~.,data=train, method = "glmnet")
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
model
c(1:10)/10
plot(mmodel
)
plot(model)
myGrid = expand.grid(n.trees = c(1:2)
, interaction.depth = c(1:2), shrinkage =c(1:2)
, n.minobsinnode = c(1:2)  )
model= train(overall~.,data=train, method = "gbm",tuneGrid = myGrid)
# Plot tuning parameters
plot(model)
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
postResample(pred = pred, obs = test$overall)
plot(model)
myGrid = expand.grid(size = c(1:3))
model <- train(overall~.,data = train, method = "mlp", tuneGrid = myGrid)
sum(is.na(train))
model
plot(model)
pred  = predict(model, test)
# Show performance of the model on test data
postResample(pred = pred, obs = test$overall)
library(caret)
library(neuralnet)
#want to make one nerual network not sure how to go about it
myGrid = expand.grid(size = c(3, 5))
model <- train(overall~.,data = train, method = "mlp", tuneGrid = myGrid)
pred  = predict(model, test)
# Show performance of the model on test data
postResample(pred = pred, obs = test$overall)
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
options(warn=-1)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=.3
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
# splirtule can be "variance", "extratrees", "maxstat"
myGrid = expand.grid(mtry = c(1:2), splitrule='variance',
min.node.size = c(1:2))
model <- train(overall~.,data = train, method = "ranger", tuneGrid = myGrid)
# Plot tuning parameters
plot(model)
pred  = predict(model, test)
# Show performance of the model on test data
postResample(pred = pred, obs = test$overall)
myGrid = expand.grid(n.trees = c(1:2)
, interaction.depth = c(1:2), shrinkage =c(1:2)
, n.minobsinnode = c(1:2)  )
model= train(overall~.,data=train, method = "gbm",tuneGrid = myGrid)
# Plot tuning parameters
plot(model)
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
library(lars)
myGrid = expand.grid(alpha = c(1:10)/10, lambda = c(1:10)/10)
model= train(overall~.,data=train, method = "glmnet")
# Plot tuning parameters
plot(model)
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
options(warn=-1)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=1
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
train = train %>% mutate_if(is.character, as.numeric)
train = train[complete.cases(train),]
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
library(lars)
myGrid = expand.grid(alpha = c(1:10)/10, lambda = c(1:10)/10)
model= train(overall~.,data=train, method = "glmnet")
# Plot tuning parameters
plot(model)
pred = predict(model,test)
postResample(pred = pred, obs = test$overall)
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
library(tidyverse)
library(purrr)
library(caret)
library(rpart)
library(rattle)
library(ranger)
library(stats)
options(warn=-1)
Fifa_19 = read_csv("players_19.csv")
Fifa_20 = read_csv("players_20.csv")
set.seed(1234)
p=.3
splitIndex = createDataPartition(Fifa_19$overall, p=p, list = FALSE)
train= Fifa_19[splitIndex,]
splitIndex = createDataPartition(Fifa_20$overall, p=p, list = FALSE)
test = Fifa_20[-splitIndex,]
# Some numeric variables are recognized as character.
# This is to correct the type of some variables.
train = train %>% mutate_if(is.character, as.numeric)
# Remove NA
train = train[complete.cases(train),]
# Do the same for test
test = test %>% mutate_if(is.character, as.numeric)
test = test[complete.cases(test),]
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
pred3
model
model = ranger(overall ~., data = train, mtry = 1, num.trees = 10)
pred3  = predict(model, data = test)$overall
model
