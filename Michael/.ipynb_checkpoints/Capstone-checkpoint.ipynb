{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import randint\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"RedCleanDataADM.xlsx\", encoding = \"ISO-8859-1\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.iloc[:,-1].isnull()]\n",
    "\n",
    "X = df.iloc[:,7:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X1 = X.select_dtypes(exclude=['object'])\n",
    "X2 = imputer.fit_transform(X1)\n",
    "X2 = pd.DataFrame(data=X2, columns=X1.columns)\n",
    "X3 = pd.concat([X.select_dtypes(include=['object']), X2], axis=1)\n",
    "X = X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUMBRANCH        0\n",
       "PREDDEG          0\n",
       "HIGHDEG          0\n",
       "CONTROL          0\n",
       "ST_FIPS          0\n",
       "REGION           0\n",
       "LOCALE           0\n",
       "LATITUDE         0\n",
       "LONGITUDE        0\n",
       "CCBASIC          0\n",
       "CCUGPROF         0\n",
       "CCSIZSET         0\n",
       "HBCU             0\n",
       "MENONLY          0\n",
       "WOMENONLY        0\n",
       "RELAFFIL         0\n",
       "ACTCMMID         0\n",
       "SAT_AVG_ALL      0\n",
       "DISTANCEONLY     0\n",
       "UGDS             0\n",
       "UGDS_WHITE       0\n",
       "UGDS_BLACK       0\n",
       "UGDS_HISP        0\n",
       "UGDS_ASIAN       0\n",
       "PPTUG_EF         0\n",
       "CURROPER         0\n",
       "COSTT4_A         0\n",
       "TUITFTE          0\n",
       "INEXPFTE         0\n",
       "PCTPELL          0\n",
       "UG25ABV          0\n",
       "GRAD_DEBT_MDN    0\n",
       "DEBT_N           0\n",
       "ICLEVEL          0\n",
       "UGDS_MEN         0\n",
       "UGDS_WOMEN       0\n",
       "OPENADMP         0\n",
       "SCHTYPE          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      NUMBRANCH  PREDDEG  HIGHDEG  CONTROL  ST_FIPS  REGION  LOCALE  \\\n",
      "593         1.0      3.0      4.0      1.0      8.0     7.0    12.0   \n",
      "861         2.0      3.0      4.0      1.0     30.0     7.0    33.0   \n",
      "1552        1.0      3.0      4.0      2.0     25.0     1.0    11.0   \n",
      "1318        1.0      3.0      3.0      2.0     27.0     4.0    31.0   \n",
      "1861        2.0      1.0      2.0      3.0     12.0     5.0    11.0   \n",
      "1454        1.0      1.0      3.0      2.0     37.0     5.0    12.0   \n",
      "1679        4.0      3.0      4.0      2.0     44.0     1.0    12.0   \n",
      "2048        1.0      3.0      4.0      3.0      6.0     8.0    11.0   \n",
      "1709        5.0      2.0      2.0      1.0     72.0     9.0    13.0   \n",
      "204         1.0      3.0      3.0      2.0     26.0     3.0    13.0   \n",
      "1715        1.0      3.0      4.0      2.0     72.0     9.0    21.0   \n",
      "606         1.0      3.0      4.0      1.0     10.0     2.0    13.0   \n",
      "1508        1.0      3.0      4.0      2.0     10.0     2.0    21.0   \n",
      "921         2.0      3.0      4.0      2.0     36.0     2.0    13.0   \n",
      "2104        1.0      3.0      4.0      2.0     37.0     5.0    21.0   \n",
      "466         1.0      3.0      4.0      2.0     49.0     7.0    12.0   \n",
      "1507        1.0      3.0      4.0      1.0      9.0     1.0    13.0   \n",
      "806         1.0      3.0      4.0      1.0     26.0     3.0    21.0   \n",
      "1890        1.0      2.0      3.0      2.0     36.0     2.0    21.0   \n",
      "1427        1.0      3.0      4.0      2.0     55.0     3.0    11.0   \n",
      "523         1.0      3.0      4.0      1.0      1.0     5.0    12.0   \n",
      "1575        1.0      3.0      3.0      2.0     33.0     1.0    42.0   \n",
      "1554        3.0      1.0      4.0      2.0     25.0     1.0    12.0   \n",
      "1802       14.0      3.0      3.0      3.0     13.0     5.0    12.0   \n",
      "449         1.0      3.0      4.0      2.0     48.0     6.0    23.0   \n",
      "100         1.0      3.0      4.0      2.0     17.0     3.0    11.0   \n",
      "1121        1.0      3.0      4.0      1.0     47.0     5.0    12.0   \n",
      "1694        1.0      3.0      4.0      1.0     51.0     5.0    12.0   \n",
      "446         1.0      3.0      4.0      2.0     48.0     6.0    11.0   \n",
      "745         1.0      3.0      4.0      1.0     23.0     1.0    13.0   \n",
      "...         ...      ...      ...      ...      ...     ...     ...   \n",
      "1005        3.0      3.0      4.0      1.0     39.0     3.0    31.0   \n",
      "1829        1.0      2.0      2.0      3.0      6.0     8.0    11.0   \n",
      "1417        1.0      3.0      3.0      2.0     42.0     2.0    32.0   \n",
      "1288        1.0      3.0      4.0      2.0     12.0     5.0    21.0   \n",
      "1358        1.0      3.0      4.0      2.0     36.0     2.0    11.0   \n",
      "1636        1.0      3.0      4.0      2.0     36.0     2.0    11.0   \n",
      "1955        1.0      1.0      1.0      1.0     36.0     2.0    32.0   \n",
      "1136        1.0      3.0      4.0      1.0     48.0     6.0    41.0   \n",
      "1028        1.0      3.0      4.0      1.0     41.0     8.0    12.0   \n",
      "961         1.0      3.0      4.0      1.0     37.0     5.0    13.0   \n",
      "1146        1.0      3.0      4.0      1.0     48.0     6.0    32.0   \n",
      "129         1.0      3.0      4.0      2.0     19.0     4.0    33.0   \n",
      "953         1.0      3.0      4.0      2.0     36.0     2.0    12.0   \n",
      "1562        1.0      3.0      4.0      2.0     25.0     1.0    12.0   \n",
      "950         1.0      3.0      4.0      1.0     36.0     2.0    21.0   \n",
      "1117        1.0      3.0      4.0      1.0     46.0     4.0    33.0   \n",
      "1886        1.0      1.0      1.0      2.0     36.0     2.0    32.0   \n",
      "254         1.0      3.0      4.0      2.0     31.0     4.0    11.0   \n",
      "881         2.0      3.0      4.0      2.0     34.0     2.0    21.0   \n",
      "1943        1.0      1.0      1.0      1.0     25.0     1.0    21.0   \n",
      "1606        2.0      2.0      2.0      1.0     36.0     2.0    41.0   \n",
      "1261        5.0      3.0      4.0      1.0      9.0     1.0    12.0   \n",
      "93          1.0      3.0      4.0      2.0     17.0     3.0    32.0   \n",
      "1083        1.0      3.0      4.0      1.0     42.0     2.0    32.0   \n",
      "670         1.0      3.0      4.0      1.0     17.0     3.0    22.0   \n",
      "1277        5.0      3.0      4.0      2.0      4.0     6.0    11.0   \n",
      "816         1.0      3.0      4.0      2.0     26.0     3.0    13.0   \n",
      "1205        1.0      3.0      4.0      2.0     54.0     5.0    13.0   \n",
      "1789        1.0      3.0      3.0      2.0     36.0     2.0    11.0   \n",
      "120         1.0      3.0      4.0      2.0     18.0     3.0    11.0   \n",
      "\n",
      "       LATITUDE   LONGITUDE  CCBASIC  ...  INEXPFTE  PCTPELL  UG25ABV  \\\n",
      "593   40.410855 -104.692777     17.0  ...   10145.0   0.2923  0.11230   \n",
      "861   46.012868 -112.559511     20.0  ...    8434.0   0.2983  0.24890   \n",
      "1552  42.355253  -71.074125     22.0  ...    7640.0   0.4544  0.47180   \n",
      "1318  44.323626  -93.972196     21.0  ...   15347.0   0.2436  0.00920   \n",
      "1861  30.238860  -81.581748     10.0  ...    6817.0   0.6598  0.64250   \n",
      "1454  35.058616  -78.961305     24.0  ...    1103.0   0.3084  0.55380   \n",
      "1679  41.819956  -71.412770     18.0  ...    6559.0   0.3619  0.08180   \n",
      "2048  33.697112 -117.835761     29.0  ...     495.0   0.0022  0.08100   \n",
      "1709  17.977897  -66.118728      7.0  ...    8253.0   0.7663  0.17360   \n",
      "204   42.787298  -86.102089     21.0  ...   11969.0   0.1827  0.01210   \n",
      "1715  18.182777  -66.303153     22.0  ...    2994.0   0.9427  0.13580   \n",
      "606   39.187173  -75.540530     16.0  ...   13084.0   0.4931  0.06000   \n",
      "1508  39.741501  -75.689624     29.0  ...    3176.0   0.3642  0.16340   \n",
      "921   42.729978  -73.676646     15.0  ...   17911.0   0.1703  0.01230   \n",
      "2104  35.981858  -78.513755     18.0  ...    4976.0   0.0000  0.39160   \n",
      "466   40.250851 -111.649281     16.0  ...   14412.0   0.3643  0.11950   \n",
      "1507  41.400365  -73.444264     19.0  ...   12714.0   0.3592  0.16920   \n",
      "806   42.963001  -85.889826     18.0  ...    8269.0   0.3105  0.07770   \n",
      "1890  41.268725  -73.889793     24.0  ...   12808.0   0.5169  0.64285   \n",
      "1427  42.982842  -87.965174     19.0  ...    8313.0   0.5633  0.29420   \n",
      "523   32.367360  -86.177544     18.0  ...    7487.0   0.4416  0.22440   \n",
      "1575  43.411663  -71.975805     22.0  ...    8620.0   0.2716  0.06820   \n",
      "1554  42.378657  -71.123479     30.0  ...   14847.0   0.1364  0.10870   \n",
      "1802  33.911943  -84.351949     26.0  ...    6408.0   0.5271  0.71510   \n",
      "449   31.066793  -97.463471     18.0  ...    9291.0   0.4033  0.15570   \n",
      "100   41.975268  -87.709948     18.0  ...    8391.0   0.3829  0.15430   \n",
      "1121  36.533319  -87.354081     18.0  ...    8322.0   0.5115  0.26720   \n",
      "1694  37.062495  -76.494364     20.0  ...    8937.0   0.1469  0.01230   \n",
      "446   29.467080  -98.465830     17.0  ...    8506.0   0.3877  0.37790   \n",
      "745   43.662863  -70.274247     18.0  ...    8604.0   0.3551  0.28850   \n",
      "...         ...         ...      ...  ...       ...      ...      ...   \n",
      "1005  39.507757  -84.732954     16.0  ...   11720.0   0.1096  0.01740   \n",
      "1829  34.101218 -118.327933     12.0  ...    4475.0   0.6809  0.58490   \n",
      "1417  40.797502  -76.875329     21.0  ...   11097.0   0.2569  0.01790   \n",
      "1288  25.742579  -80.337411     24.0  ...   17663.0   0.2459  0.16070   \n",
      "1358  40.713812  -73.991271     24.0  ...   26925.0   0.6250  0.04080   \n",
      "1636  40.703795  -73.834252     24.0  ...   12425.0   0.0946  0.42860   \n",
      "1955  44.693228  -73.517906     -2.0  ...   12268.0   0.6765  0.52860   \n",
      "1136  33.490482  -94.103617     19.0  ...   10370.0   0.4984  0.39750   \n",
      "1028  44.045146 -123.075792     15.0  ...   14187.0   0.2458  0.06850   \n",
      "961   35.607186  -77.368291     16.0  ...   11707.0   0.3353  0.14520   \n",
      "1146  30.092425  -95.989475     18.0  ...    7537.0   0.6469  0.10310   \n",
      "129   42.642255  -95.208529     19.0  ...    7587.0   0.4466  0.37800   \n",
      "953   43.040176  -76.136975     15.0  ...   17059.0   0.2137  0.03260   \n",
      "1562  42.274853  -71.808339     16.0  ...   19378.0   0.1216  0.01170   \n",
      "950   40.799021  -73.571907     20.0  ...   11705.0   0.4877  0.23060   \n",
      "1117  45.450829  -98.484728     20.0  ...    8721.0   0.1707  0.12490   \n",
      "1886  42.877660  -76.988902     -2.0  ...    2455.0   0.6667  0.48390   \n",
      "254   41.259165  -95.974847     26.0  ...   10934.0   0.3299  0.40430   \n",
      "881   40.280066  -74.006447     18.0  ...   10004.0   0.2785  0.03680   \n",
      "1943  42.653908  -71.386180     -2.0  ...    5518.0   0.3659  0.53160   \n",
      "1606  42.867556  -77.241801      3.0  ...    5826.0   0.2764  0.18000   \n",
      "1261  41.762673  -72.672175     -2.0  ...    8470.0   0.4089  0.07190   \n",
      "93    40.148924  -89.346721     24.0  ...    5917.0   0.4461  0.26180   \n",
      "1083  41.062719  -80.045965     18.0  ...    8539.0   0.3132  0.07360   \n",
      "670   40.509403  -88.990058     16.0  ...   15761.0   0.2755  0.04440   \n",
      "1277  33.572173 -112.113001     20.0  ...    1631.0   0.5333  0.82940   \n",
      "816   43.628717  -84.276820     29.0  ...    6264.0   0.3095  0.43710   \n",
      "1205  38.333367  -81.616244     17.0  ...    6854.0   0.3038  0.39540   \n",
      "1789  40.638194  -73.987855     24.0  ...    4265.0   0.8010  0.00480   \n",
      "120   39.813233  -86.202643     19.0  ...   11304.0   0.2455  0.26230   \n",
      "\n",
      "      GRAD_DEBT_MDN   DEBT_N  ICLEVEL  UGDS_MEN  UGDS_WOMEN  OPENADMP  SCHTYPE  \n",
      "593         20495.0   5815.0      1.0    0.3466      0.6534       2.0      1.0  \n",
      "861         20000.0   1261.0      1.0    0.6799      0.3201       2.0      1.0  \n",
      "1552        22420.0   1288.0      1.0    0.3302      0.6698       2.0      2.0  \n",
      "1318        27000.0    977.0      1.0    0.4382      0.5618       2.0      2.0  \n",
      "1861         9500.0   1391.0      2.0    0.1159      0.8841       2.0      3.0  \n",
      "1454        22317.0     36.0      1.0    0.6063      0.3937       2.0      2.0  \n",
      "1679        24500.0  10986.0      1.0    0.4017      0.5983       2.0      2.0  \n",
      "2048        22317.0     17.0      1.0    0.6418      0.3582       2.0      3.0  \n",
      "1709        22317.0    149.5      2.0    0.5981      0.4019       2.0      1.0  \n",
      "204         26920.0   1203.0      1.0    0.3863      0.6137       2.0      2.0  \n",
      "1715         3400.0    582.0      1.0    0.3739      0.6261       2.0      2.0  \n",
      "606         27000.0   2357.0      1.0    0.3488      0.6512       2.0      1.0  \n",
      "1508        19500.0    312.0      1.0    0.4403      0.5597       2.0      2.0  \n",
      "921         25500.0   2156.0      1.0    0.6801      0.3199       2.0      2.0  \n",
      "2104        22317.0    149.5      1.0    0.6995      0.3005       2.0      2.0  \n",
      "466         12100.0   6652.0      1.0    0.5129      0.4871       2.0      2.0  \n",
      "1507        25000.0   2687.0      1.0    0.4830      0.5170       2.0      1.0  \n",
      "806         24750.0  11637.0      1.0    0.4110      0.5890       2.0      1.0  \n",
      "1890        18607.0    260.0      1.0    1.0000      0.0000       2.0      2.0  \n",
      "1427        31000.0   1126.0      1.0    0.0039      0.9961       2.0      2.0  \n",
      "523         25000.0   2624.0      1.0    0.3583      0.6417       2.0      1.0  \n",
      "1575        27000.0    625.0      1.0    0.3001      0.6999       2.0      2.0  \n",
      "1554        26000.0    736.0      1.0    0.3913      0.6087       2.0      2.0  \n",
      "1802        22342.0  23154.0      1.0    0.1003      0.8997       2.0      3.0  \n",
      "449         26000.0   1918.0      1.0    0.3563      0.6437       2.0      2.0  \n",
      "100         25000.0   1327.0      1.0    0.3697      0.6303       2.0      2.0  \n",
      "1121        22355.0   5875.0      1.0    0.4163      0.5837       2.0      1.0  \n",
      "1694        25000.0   1805.0      1.0    0.4374      0.5626       2.0      1.0  \n",
      "446         27666.0   3702.0      1.0    0.3976      0.6024       2.0      2.0  \n",
      "745         21322.0   3752.0      1.0    0.4192      0.5808       2.0      1.0  \n",
      "...             ...      ...      ...       ...         ...       ...      ...  \n",
      "1005        23250.0   7450.0      1.0    0.4973      0.5027       2.0      1.0  \n",
      "1829        22317.0     42.0      2.0    0.6415      0.3585       2.0      3.0  \n",
      "1417        27000.0   1005.0      1.0    0.4402      0.5598       2.0      2.0  \n",
      "1288        22317.0    149.5      1.0    0.9821      0.0179       2.0      2.0  \n",
      "1358        13210.0    176.5      1.0    1.0000      0.0000       2.0      2.0  \n",
      "1636        18607.0    260.0      1.0    1.0000      0.0000       2.0      2.0  \n",
      "1955         8700.0     67.0      2.0    0.2429      0.7571       2.0      1.0  \n",
      "1136        16000.0   1092.0      1.0    0.3879      0.6121       2.0      1.0  \n",
      "1028        20767.0   6724.0      1.0    0.4643      0.5357       2.0      1.0  \n",
      "961         24250.0  11683.0      1.0    0.4339      0.5661       2.0      1.0  \n",
      "1146        29902.0   4901.0      1.0    0.3905      0.6095       2.0      1.0  \n",
      "129         24912.0   1765.0      1.0    0.3641      0.6359       2.0      2.0  \n",
      "953         27000.0   5502.0      1.0    0.4608      0.5392       2.0      2.0  \n",
      "1562        27000.0   1771.0      1.0    0.6401      0.3599       2.0      2.0  \n",
      "950         16844.0   1944.0      1.0    0.4055      0.5945       2.0      1.0  \n",
      "1117        22616.0   1119.0      1.0    0.4321      0.5679       2.0      1.0  \n",
      "1886        14735.0    219.0      3.0    0.0000      1.0000       2.0      2.0  \n",
      "254         25500.0    544.0      1.0    0.1431      0.8569       2.0      2.0  \n",
      "881         26500.0   2436.0      1.0    0.4213      0.5787       2.0      2.0  \n",
      "1943        22317.0     67.0      3.0    0.1646      0.8354       2.0      1.0  \n",
      "1606        12000.0   2804.0      2.0    0.4445      0.5555       1.0      1.0  \n",
      "1261        21500.0   9663.0      1.0    0.4285      0.5715       2.0      1.0  \n",
      "93          23500.0    307.0      1.0    0.4932      0.5068       2.0      2.0  \n",
      "1083        25000.0   4556.0      1.0    0.4333      0.5667       2.0      1.0  \n",
      "670         20000.0   9246.0      1.0    0.4477      0.5523       2.0      1.0  \n",
      "1277        21772.0   2092.0      1.0    0.2675      0.7325       1.0      2.0  \n",
      "816         21500.0   1985.0      1.0    0.5757      0.4243       2.0      2.0  \n",
      "1205        21000.0    967.0      1.0    0.5508      0.4492       2.0      2.0  \n",
      "1789        22317.0    149.5      1.0    1.0000      0.0000       2.0      2.0  \n",
      "120         26125.0   1501.0      1.0    0.3801      0.6199       2.0      2.0  \n",
      "\n",
      "[428 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 0.01689878597549835\n",
      "Mean Squared Error on Testing 0.024141923821822273\n",
      "Rsquared on Training 0.601428376672746\n",
      "Rsquared on Testing 0.4564507798529678\n",
      "Mean Absolute Error on Training 0.10314218367599615\n",
      "Mean Absolute Error on Testing 0.1213122321180685\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.223, 'n_estimators': 23}\n",
      "Mean Squared Error on Training 0.020415808837216578\n",
      "Mean Squared Error on Testing 0.029800176467451492\n",
      "Rsquared on Training 0.5209047305559835\n",
      "Rsquared on Testing 0.31753964044337013\n",
      "Mean Absolute Error on Training 0.1128964645199872\n",
      "Mean Absolute Error on Testing 0.13552742765641973\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Male\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 25, 2), 'learning_rate':np.linspace(0.001, 1, 10)}\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 0.0033590958549012833\n",
      "Mean Squared Error on Testing 0.02701679626800218\n",
      "Rsquared on Training 0.9211725116293937\n",
      "Rsquared on Testing 0.3812824392074552\n",
      "Mean Absolute Error on Training 0.04459075615452478\n",
      "Mean Absolute Error on Testing 0.12381194173937277\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'max_features': 4, 'n_estimators': 12}\n",
      "Mean Squared Error on Training 0.004735079143599669\n",
      "Mean Squared Error on Testing 0.029080912431047445\n",
      "Rsquared on Training 0.8888824814030285\n",
      "Rsquared on Testing 0.3340116634676834\n",
      "Mean Absolute Error on Training 0.05078732603083264\n",
      "Mean Absolute Error on Testing 0.13324224325001666\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {\"n_estimators\":range(2, 20), \"max_features\":range(1, 5)}\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 0.027637265520715007\n",
      "Mean Squared Error on Testing 0.034350194684504766\n",
      "Rsquared on Training 0.35143969671161934\n",
      "Rsquared on Testing 0.2133386780164872\n",
      "Mean Absolute Error on Training 0.13761932648139566\n",
      "Mean Absolute Error on Testing 0.1528294298933748\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.223, 'n_estimators': 7}\n",
      "Mean Squared Error on Training 111.07344340870546\n",
      "Mean Squared Error on Testing 111.42126499977901\n",
      "Rsquared on Training 0.14916234030573483\n",
      "Rsquared on Testing 0.1443280866107297\n",
      "Mean Absolute Error on Training 7.093883897316819\n",
      "Mean Absolute Error on Testing 7.094252929936963\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 0.022673732722875442\n",
      "Mean Squared Error on Testing 0.03813916742654859\n",
      "Rsquared on Training 0.4679183090524748\n",
      "Rsquared on Testing 0.1265665844783902\n",
      "Mean Absolute Error on Training 0.11478557692672438\n",
      "Mean Absolute Error on Testing 0.1487369410370318\n"
     ]
    }
   ],
   "source": [
    "#Male KNN\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'n_neighbors': 10}\n",
      "Mean Squared Error on Training 0.026216166179088344\n",
      "Mean Squared Error on Testing 0.036804256478359006\n",
      "Rsquared on Training 0.38478845979085696\n",
      "Rsquared on Testing 0.15713767209166618\n",
      "Mean Absolute Error on Training 0.12489206149217538\n",
      "Mean Absolute Error on Testing 0.14767363220814683\n"
     ]
    }
   ],
   "source": [
    "#KNN Male Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2, 20, 2)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.15170651624653786\n",
      "Rsquared on Testing 0.1930181748990103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Rsquared on Training 0.26332176994330914\n",
      "Rsquared on Testing 0.3203178968978384\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = {'alpha':np.linspace(0,10, 10), 'l1_ratio':np.linspace(0,1,10)}\n",
    "model = GridSearchCV(ElasticNet(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
