{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"RedCleanData.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"UNITID\", \"OPEID\", \"OPEID6\", \"INSTNM\", \"CITY\", \"STABBR\", \"ZIP\", \"NUMBRANCH\", \"PREDDEG\", \"HIGHDEG\", \"CONTROL\", \"ST_FIPS\", \"REGION\", \"LOCALE\", \"LATITUDE\", \"LONGITUDE\", \"CCBASIC\", \"CCUGPROF\", \"CCSIZSET\", \"HBCU\", \"MENONLY\", \"WOMENONLY\", \"RELAFFIL\", \"ACTCMMID\", \"SAT_AVG_ALL\", \"DISTANCEONLY\", \"UGDS\", \"UGDS_WHITE\", \"UGDS_BLACK\", \"UGDS_HISP\", \"UGDS_ASIAN\", \"PPTUG_EF\", \"CURROPER\", \"COSTT4_A\", \"TUITFTE\", \"INEXPFTE\", \"PCTPELL\", \"UG25ABV\", \"GRAD_DEBT_MDN\", \"DEBT_N\", \"ICLEVEL\", \"UGDS_MEN\", \"UGDS_WOMEN\", \"OPENADMP\", \"SCHTYPE\"]]\n",
    "y = df[[\"ADM_RATE_ALL\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Creating new data framimp_mean = IterativeImputer(random_state=0)es to be used in future models\n",
    "x = College.iloc[:, 1:45].values\n",
    "y = College.iloc[:, 45:46].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "imputer=imputer.fit(x[:,7:45])\n",
    "x[:,7:45]=imputer.transform(x[:,7:45])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imputer=imputer.fit(y[:, 45:46])\n",
    "y[:, 45:46]=imputer.transform(y[:, 45:46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 106.59522877013674\n",
      "Mean Squared Error on Testing 108.02257701390026\n",
      "Rsquared on Training 0.1834660725549303\n",
      "Rsquared on Testing 0.1704286864548955\n",
      "Mean Absolute Error on Training 6.837087457655009\n",
      "Mean Absolute Error on Testing 6.87041799072593\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Male\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.445, 'n_estimators': 23}\n",
      "Mean Squared Error on Training 106.59463325786454\n",
      "Mean Squared Error on Testing 108.0006339242444\n",
      "Rsquared on Training 0.1834706342598028\n",
      "Rsquared on Testing 0.17059720083598384\n",
      "Mean Absolute Error on Training 6.8376644436192455\n",
      "Mean Absolute Error on Testing 6.874582868613409\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Male\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 25, 2), 'learning_rate':np.linspace(0.001, 1, 10)}\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632.0266580873151"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.445, n_estimators=23)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "prediction = model.predict(x_out_m)\n",
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.3197932  44.43270667 35.65055247 42.95485399 42.06885922 32.44001311\n",
      " 39.10038955 43.20930998 40.99858587 33.63354132 41.47184904 41.2212307\n",
      " 44.64945738 41.062145   39.20681564 35.60655494]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'learning_rate': 0.334, 'n_estimators': 49}\n",
      "Mean Squared Error on Training 106.00270769290321\n",
      "Mean Squared Error on Testing 110.83462565629831\n",
      "Rsquared on Training 0.1788758727943388\n",
      "Rsquared on Testing 0.17358495880805902\n",
      "Mean Absolute Error on Training 6.739322035535725\n",
      "Mean Absolute Error on Testing 6.839502200531901\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001, 1, 10)}\n",
    "\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1165.9256783240437"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.334, n_estimators=49)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "prediction = model.predict(x_out_f)\n",
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Male\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Female\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'max_features': 4, 'n_estimators': 18}\n",
      "Mean Squared Error on Training 84.79238683126026\n",
      "Mean Squared Error on Testing 122.80355911794001\n",
      "Rsquared on Training 0.3504788025168406\n",
      "Rsquared on Testing 0.056916501516398044\n",
      "Mean Absolute Error on Training 6.061903877314406\n",
      "Mean Absolute Error on Testing 7.420212688190928\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning Male\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {\"n_estimators\":range(2, 20), \"max_features\":range(1, 5)}\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'max_features': 4, 'n_estimators': 19}\n",
      "Mean Squared Error on Training 82.03820691193577\n",
      "Mean Squared Error on Testing 126.06781262055344\n",
      "Rsquared on Training 0.3645110345366146\n",
      "Rsquared on Testing 0.06000190876385958\n",
      "Mean Absolute Error on Training 6.007157302670192\n",
      "Mean Absolute Error on Testing 7.622343915794152\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {\"n_estimators\":range(2, 20), \"max_features\":range(1, 5)}\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 128.58656891403822\n",
      "Mean Squared Error on Testing 129.37326605531462\n",
      "Rsquared on Training 0.015009420745473845\n",
      "Rsquared on Testing 0.006463711328445587\n",
      "Mean Absolute Error on Training 8.404467155884372\n",
      "Mean Absolute Error on Testing 8.388904377866522\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Male\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 113.87831658583328\n",
      "Mean Squared Error on Testing 118.12191316032862\n",
      "Rsquared on Training 0.11786938891134924\n",
      "Rsquared on Testing 0.11924883445016976\n",
      "Mean Absolute Error on Training 6.967999935750461\n",
      "Mean Absolute Error on Testing 7.044819679861824\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Female\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.223, 'n_estimators': 7}\n",
      "Mean Squared Error on Training 111.07344340870546\n",
      "Mean Squared Error on Testing 111.42126499977901\n",
      "Rsquared on Training 0.14916234030573483\n",
      "Rsquared on Testing 0.1443280866107297\n",
      "Mean Absolute Error on Training 7.093883897316819\n",
      "Mean Absolute Error on Testing 7.094252929936963\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Tuning Male\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'learning_rate': 0.112, 'n_estimators': 13}\n",
      "Mean Squared Error on Training 111.73659525543746\n",
      "Mean Squared Error on Testing 115.37204912323425\n",
      "Rsquared on Training 0.1344597109551393\n",
      "Rsquared on Testing 0.13975261644096004\n",
      "Mean Absolute Error on Training 6.856201230563701\n",
      "Mean Absolute Error on Testing 6.914624796029894\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Tuning Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male KNN\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Female KNN\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'n_neighbors': 18}\n",
      "Mean Squared Error on Training 104.48338128478599\n",
      "Mean Squared Error on Testing 113.27649503409071\n",
      "Rsquared on Training 0.19964311107038724\n",
      "Rsquared on Testing 0.1300806426130342\n",
      "Mean Absolute Error on Training 6.852570308695219\n",
      "Mean Absolute Error on Testing 7.140672280413501\n"
     ]
    }
   ],
   "source": [
    "#KNN Male Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2, 20, 2)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'n_neighbors': 18}\n",
      "Mean Squared Error on Training 104.45737279085965\n",
      "Mean Squared Error on Testing 117.43833591663254\n",
      "Rsquared on Training 0.19084643279509916\n",
      "Rsquared on Testing 0.12434578418642639\n",
      "Mean Absolute Error on Training 6.89890900431761\n",
      "Mean Absolute Error on Testing 7.260101674757755\n"
     ]
    }
   ],
   "source": [
    "#KNN Female Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2, 20, 2)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male Model Logistic\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy Male:', model.score(x_train_m, y_train_m.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_log_pred_m = model.predict(x_test_m)\n",
    "print('Testing Accuracy Male:', metrics.accuracy_score(y_log_pred_m, y_test_m))\n",
    "print('Testing Accuracy - Balanced Male:', \tmetrics.balanced_accuracy_score (y_test_m, y_log_pred_m)) \n",
    "\n",
    "cm_rf_tun_m = metrics.confusion_matrix(y_rf_pred_tun_m, y_test_m)\n",
    "\n",
    "cm_log_m_df = pd.DataFrame(cm_log_m, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "print(cm_log_m_df)\n",
    "\n",
    "sensitivity_rf_tun_m = cm_rf_tun_m[0,0]/(cm_rf_tun_m[0,0]+cm_rf_tun_m[0,1])\n",
    "print('Sensitivity Male: ', sensitivity_rf_tun_m)\n",
    "\n",
    "specificity_rf_tun_m = cm_rf_tun_m[1,1]/(cm_rf_tun_m[1,0]+cm_rf_tun_m[1,1])\n",
    "print('Specificity Male: ', specificity_rf_tun_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=.1, l1_ratio=1)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_lasso_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_lasso_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=.1, l1_ratio=0)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ridge_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ridge_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=1, l1_ratio=.1)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ela_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ela_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'alpha':np.linspace(0.1,10, 10), 'l1_ratio':np.linspace(0,1,10)}\n",
    "\n",
    "model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ela_pred_tun = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ela_pred_tun, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL ACCURARCY RESULTS:\")\n",
    "# knn, logistic, lasso, ridge, elastic net\n",
    "\n",
    "print(\"\\nGradient Boosting: \", metrics.accuracy_score(y_grad_pred, y_test))\n",
    "print(\"Gradient Boosting Tuning: \", metrics.accuracy_score(y_grad_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nRandom Forest:\", metrics.accuracy_score(y_rf_pred, y_test))\n",
    "print(\"Random Forest Tuning:\", metrics.accuracy_score(y_rf_pred_tun, y_test.values.ravel()))\n",
    "\n",
    "print(\"\\nAdaboost: \", metrics.accuracy_score(y_ada_pred, y_test))\n",
    "print(\"Adaboost Tuning: \",metrics.accuracy_score(y_ada_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nDecision Tree: \", metrics.accuracy_score(y_tree_pred, y_test))\n",
    "print(\"Decision Tree Tuning: \", metrics.accuracy_score(y_tree_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nKNN: \", metrics.accuracy_score(y_knn_pred, y_test))\n",
    "print(\"KNN Tuning: \", metrics.accuracy_score(y_knn_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nLogistic Regression: \", metrics.accuracy_score(y_log_pred, y_test))\n",
    "\n",
    "print(\"Lasso: \", metrics.accuracy_score(y_lasso_pred, y_test))\n",
    "\n",
    "print(\"Ridge:\", metrics.accuracy_score(y_ridge_pred, y_test))\n",
    "\n",
    "print(\"\\nElastic Net:\", metrics.accuracy_score(y_ela_pred, y_test))\n",
    "print(\"Elastic Net Tuning:\", metrics.accuracy_score(y_ela_pred_tun, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
