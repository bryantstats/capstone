{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import randint\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C://Capstone/RedCleanData.xlsx\", index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"UNITID\", \"OPEID\", \"OPEID6\", \"INSTNM\", \"CITY\", \"STABBR\", \"ZIP\", \"NUMBRANCH\", \"PREDDEG\", \"HIGHDEG\", \"CONTROL\", \"ST_FIPS\", \"REGION\", \"LOCALE\", \"LATITUDE\", \"LONGITUDE\", \"CCBASIC\", \"CCUGPROF\", \"CCSIZSET\", \"HBCU\", \"MENONLY\", \"WOMENONLY\", \"RELAFFIL\", \"ACTCMMID\", \"SAT_AVG_ALL\", \"DISTANCEONLY\", \"UGDS\", \"UGDS_WHITE\", \"UGDS_BLACK\", \"UGDS_HISP\", \"UGDS_ASIAN\", \"PPTUG_EF\", \"CURROPER\", \"COSTT4_A\", \"TUITFTE\", \"INEXPFTE\", \"PCTPELL\", \"UG25ABV\", \"GRAD_DEBT_MDN\", \"DEBT_N\", \"ICLEVEL\", \"UGDS_MEN\", \"UGDS_WOMEN\", \"OPENADMP\", \"SCHTYPE\"]]\n",
    "y = df[[\"ADM_RATE_ALL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Birmingham Southern College'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-846be93ed097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtransformed_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\imputation.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             X = check_array(X, accept_sparse='csc', dtype=np.float64,\n\u001b[1;32m--> 154\u001b[1;33m                             force_all_finite=False)\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Birmingham Southern College'"
     ]
    }
   ],
   "source": [
    "#Imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp.fit(self,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-2312c1158edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "help(type(self))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:,46].values\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "imputer=imputer.fit(X[:,1:3])\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Creating new data framimp_mean = IterativeImputer(random_state=0)es to be used in future models\n",
    "x = College.iloc[:, 1:45].values\n",
    "y = College.iloc[:, 45:46].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "imputer=imputer.fit(x[:,7:45])\n",
    "x[:,7:45]=imputer.transform(x[:,7:45])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imputer=imputer.fit(y[:, 45:46])\n",
    "y[:, 45:46]=imputer.transform(y[:, 45:46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 106.59522877013674\n",
      "Mean Squared Error on Testing 108.02257701390026\n",
      "Rsquared on Training 0.1834660725549303\n",
      "Rsquared on Testing 0.1704286864548955\n",
      "Mean Absolute Error on Training 6.837087457655009\n",
      "Mean Absolute Error on Testing 6.87041799072593\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Male\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.445, 'n_estimators': 23}\n",
      "Mean Squared Error on Training 106.59463325786454\n",
      "Mean Squared Error on Testing 108.0006339242444\n",
      "Rsquared on Training 0.1834706342598028\n",
      "Rsquared on Testing 0.17059720083598384\n",
      "Mean Absolute Error on Training 6.8376644436192455\n",
      "Mean Absolute Error on Testing 6.874582868613409\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Male\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 25, 2), 'learning_rate':np.linspace(0.001, 1, 10)}\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632.0266580873151"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.445, n_estimators=23)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "prediction = model.predict(x_out_m)\n",
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.3197932  44.43270667 35.65055247 42.95485399 42.06885922 32.44001311\n",
      " 39.10038955 43.20930998 40.99858587 33.63354132 41.47184904 41.2212307\n",
      " 44.64945738 41.062145   39.20681564 35.60655494]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'learning_rate': 0.334, 'n_estimators': 49}\n",
      "Mean Squared Error on Training 106.00270769290321\n",
      "Mean Squared Error on Testing 110.83462565629831\n",
      "Rsquared on Training 0.1788758727943388\n",
      "Rsquared on Testing 0.17358495880805902\n",
      "Mean Absolute Error on Training 6.739322035535725\n",
      "Mean Absolute Error on Testing 6.839502200531901\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001, 1, 10)}\n",
    "\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1165.9256783240437"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.334, n_estimators=49)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "prediction = model.predict(x_out_f)\n",
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Male\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train, model.predict(x_train)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Female\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'max_features': 4, 'n_estimators': 18}\n",
      "Mean Squared Error on Training 84.79238683126026\n",
      "Mean Squared Error on Testing 122.80355911794001\n",
      "Rsquared on Training 0.3504788025168406\n",
      "Rsquared on Testing 0.056916501516398044\n",
      "Mean Absolute Error on Training 6.061903877314406\n",
      "Mean Absolute Error on Testing 7.420212688190928\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning Male\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {\"n_estimators\":range(2, 20), \"max_features\":range(1, 5)}\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'max_features': 4, 'n_estimators': 19}\n",
      "Mean Squared Error on Training 82.03820691193577\n",
      "Mean Squared Error on Testing 126.06781262055344\n",
      "Rsquared on Training 0.3645110345366146\n",
      "Rsquared on Testing 0.06000190876385958\n",
      "Mean Absolute Error on Training 6.007157302670192\n",
      "Mean Absolute Error on Testing 7.622343915794152\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {\"n_estimators\":range(2, 20), \"max_features\":range(1, 5)}\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 128.58656891403822\n",
      "Mean Squared Error on Testing 129.37326605531462\n",
      "Rsquared on Training 0.015009420745473845\n",
      "Rsquared on Testing 0.006463711328445587\n",
      "Mean Absolute Error on Training 8.404467155884372\n",
      "Mean Absolute Error on Testing 8.388904377866522\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Male\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training 113.87831658583328\n",
      "Mean Squared Error on Testing 118.12191316032862\n",
      "Rsquared on Training 0.11786938891134924\n",
      "Rsquared on Testing 0.11924883445016976\n",
      "Mean Absolute Error on Training 6.967999935750461\n",
      "Mean Absolute Error on Testing 7.044819679861824\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Female\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'learning_rate': 0.223, 'n_estimators': 7}\n",
      "Mean Squared Error on Training 111.07344340870546\n",
      "Mean Squared Error on Testing 111.42126499977901\n",
      "Rsquared on Training 0.14916234030573483\n",
      "Rsquared on Testing 0.1443280866107297\n",
      "Mean Absolute Error on Training 7.093883897316819\n",
      "Mean Absolute Error on Testing 7.094252929936963\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Tuning Male\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'learning_rate': 0.112, 'n_estimators': 13}\n",
      "Mean Squared Error on Training 111.73659525543746\n",
      "Mean Squared Error on Testing 115.37204912323425\n",
      "Rsquared on Training 0.1344597109551393\n",
      "Rsquared on Testing 0.13975261644096004\n",
      "Mean Absolute Error on Training 6.856201230563701\n",
      "Mean Absolute Error on Testing 6.914624796029894\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Tuning Female\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1, 50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male KNN\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Female KNN\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Male Parameters are: {'n_neighbors': 18}\n",
      "Mean Squared Error on Training 104.48338128478599\n",
      "Mean Squared Error on Testing 113.27649503409071\n",
      "Rsquared on Training 0.19964311107038724\n",
      "Rsquared on Testing 0.1300806426130342\n",
      "Mean Absolute Error on Training 6.852570308695219\n",
      "Mean Absolute Error on Testing 7.140672280413501\n"
     ]
    }
   ],
   "source": [
    "#KNN Male Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2, 20, 2)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Male Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_m, model.predict(x_train_m)))\n",
    "print('Rsquared on Testing', r2_score(y_test_m, model.predict(x_test_m)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_m, model.predict(x_train_m)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_m, model.predict(x_test_m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'n_neighbors': 18}\n",
      "Mean Squared Error on Training 104.45737279085965\n",
      "Mean Squared Error on Testing 117.43833591663254\n",
      "Rsquared on Training 0.19084643279509916\n",
      "Rsquared on Testing 0.12434578418642639\n",
      "Mean Absolute Error on Training 6.89890900431761\n",
      "Mean Absolute Error on Testing 7.260101674757755\n"
     ]
    }
   ],
   "source": [
    "#KNN Female Tuning\n",
    "\n",
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2, 20, 2)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train_f, y_train_f.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best Parameters are:', model.best_params_)\n",
    "\n",
    "print('Mean Squared Error on Training', mean_squared_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Squared Error on Testing', mean_squared_error(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train_f, model.predict(x_train_f)))\n",
    "print('Rsquared on Testing', r2_score(y_test_f, model.predict(x_test_f)))\n",
    "\n",
    "print('Mean Absolute Error on Training', mean_absolute_error(y_train_f, model.predict(x_train_f)))\n",
    "print('Mean Absolute Error on Testing', mean_absolute_error(y_test_f, model.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male Model Logistic\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_m, y_train_m.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy Male:', model.score(x_train_m, y_train_m.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_log_pred_m = model.predict(x_test_m)\n",
    "print('Testing Accuracy Male:', metrics.accuracy_score(y_log_pred_m, y_test_m))\n",
    "print('Testing Accuracy - Balanced Male:', \tmetrics.balanced_accuracy_score (y_test_m, y_log_pred_m)) \n",
    "\n",
    "cm_rf_tun_m = metrics.confusion_matrix(y_rf_pred_tun_m, y_test_m)\n",
    "\n",
    "cm_log_m_df = pd.DataFrame(cm_log_m, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "print(cm_log_m_df)\n",
    "\n",
    "sensitivity_rf_tun_m = cm_rf_tun_m[0,0]/(cm_rf_tun_m[0,0]+cm_rf_tun_m[0,1])\n",
    "print('Sensitivity Male: ', sensitivity_rf_tun_m)\n",
    "\n",
    "specificity_rf_tun_m = cm_rf_tun_m[1,1]/(cm_rf_tun_m[1,0]+cm_rf_tun_m[1,1])\n",
    "print('Specificity Male: ', specificity_rf_tun_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=.1, l1_ratio=1)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_lasso_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_lasso_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=.1, l1_ratio=0)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ridge_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ridge_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=1, l1_ratio=.1)\n",
    "\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ela_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ela_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'alpha':np.linspace(0.1,10, 10), 'l1_ratio':np.linspace(0,1,10)}\n",
    "\n",
    "model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracy on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train.values.ravel()))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_ela_pred_tun = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_ela_pred_tun, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL ACCURARCY RESULTS:\")\n",
    "# knn, logistic, lasso, ridge, elastic net\n",
    "\n",
    "print(\"\\nGradient Boosting: \", metrics.accuracy_score(y_grad_pred, y_test))\n",
    "print(\"Gradient Boosting Tuning: \", metrics.accuracy_score(y_grad_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nRandom Forest:\", metrics.accuracy_score(y_rf_pred, y_test))\n",
    "print(\"Random Forest Tuning:\", metrics.accuracy_score(y_rf_pred_tun, y_test.values.ravel()))\n",
    "\n",
    "print(\"\\nAdaboost: \", metrics.accuracy_score(y_ada_pred, y_test))\n",
    "print(\"Adaboost Tuning: \",metrics.accuracy_score(y_ada_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nDecision Tree: \", metrics.accuracy_score(y_tree_pred, y_test))\n",
    "print(\"Decision Tree Tuning: \", metrics.accuracy_score(y_tree_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nKNN: \", metrics.accuracy_score(y_knn_pred, y_test))\n",
    "print(\"KNN Tuning: \", metrics.accuracy_score(y_knn_pred_tun, y_test))\n",
    "\n",
    "print(\"\\nLogistic Regression: \", metrics.accuracy_score(y_log_pred, y_test))\n",
    "\n",
    "print(\"Lasso: \", metrics.accuracy_score(y_lasso_pred, y_test))\n",
    "\n",
    "print(\"Ridge:\", metrics.accuracy_score(y_ridge_pred, y_test))\n",
    "\n",
    "print(\"\\nElastic Net:\", metrics.accuracy_score(y_ela_pred, y_test))\n",
    "print(\"Elastic Net Tuning:\", metrics.accuracy_score(y_ela_pred_tun, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
